{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TTSTacotron.ipynb","provenance":[{"file_id":"https://github.com/NVIDIA/NeMo/blob/r1.0.0rc1/tutorials/tts/2_TTS_Tacotron2_Training.ipynb","timestamp":1635318644550}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"htbJiaJjYQAD"},"source":["# Тренирање на Tacotron 2\n","\n","Во оваа вежба ќе ги претставиме чекорите потребни за тренирање на еден од најпопуларните модели за креирање на текст-во-говор.  \n","\n","Ги содржи следните секции:\n","\n","  1. Tacotron2 и NeMo - Вовед во моделот Tacotron2.\n","\n","  2. LJSpeech - Како да се истренира Tacotron2 на податочното множество LJSpeech.\n","  3. Различни јазици - Како да се соберат аудио податоци за тренирање на Tacotron2 за различни гласови и јазици."]},{"cell_type":"markdown","metadata":{"id":"wqPMTEXXYUP4"},"source":["# Лиценца\n","\n","> Copyright 2020 NVIDIA. All Rights Reserved.\n","> \n","> Apache лиценца, верзија 2.0. Оваа датотека мора да се користи согласно лиценцата која може да се преземе на следниот линк:\n","> \n",">     http://www.apache.org/licenses/LICENSE-2.0\n","> \n","> Ако не е поинаку специфицирано, кодот е дистрибуиран на база \"AS IS\", без услови и гаранции. Видете ја лиценцата за подетални информации во однос на ограничувањата."]},{"cell_type":"code","metadata":{"id":"SUkq9HAvYU7T"},"source":["\"\"\"\n","Оваа скрипта може да се извршува локално, доколку имате на располагање графичка картичка GPU или на Google Colab.\n","Инструкции за подесување на Colab:\n","1. Отворете нова Python 3 notebook.\n","2. Импортирајте од GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n","3. Поврзете се со GPU инстанца (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n","4. Извршете ја оваа ќелија за да ги вклучите сите зависности = dependencies# .\n","\"\"\"\n","# # Ако го користите Colab извршете ја оваа ќелија.\n","# !apt-get install sox libsndfile1 ffmpeg\n","# !pip install wget unidecode\n","# BRANCH = 'r1.0.0rc1'\n","# !python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[tts]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZivXzmq0YYLj"},"source":["# Tacotron2 и NeMo\n","\n","Tacotron2 е невронска мрежа која конвертира текст карактери во мел спектрограм. Повеќе детали може да се прочитаат на страницата на Nvidia's [Tacotron2 Model Card](https://ngc.nvidia.com/catalog/models/nvidia:nemo:tts_en_tacotron2), или од оригиналниот труд (https://arxiv.org/abs/1712.05884). Во оваа скрипта ќе се задржиме на практична имплементација.\n","\n","Tacotron2 како и повеќето NeMo модели е дефиниран како LightningModule, дозволувајќи лесно тренирање со PyTorch Lightning, и параметризирање преку конфигурација дефинирана во yaml датотека.\n","\n","Прво ќе видиме како да вчитаме NeMo претрениран модел и истиот да го искористиме за генерирање спектрограми."]},{"cell_type":"code","metadata":{"id":"HEvdSU5WYZbj"},"source":["# Вчитување на Tacotron2Model\n","from nemo.collections.tts.models import Tacotron2Model\n","from nemo.collections.tts.models.base import SpectrogramGenerator\n","\n","# Да ги видиме претренираните модели\n","print(Tacotron2Model.list_available_models())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3W8unatgYbUp"},"source":["# Можеме да вчитаме претрениран модел на следниот начин\n","model = Tacotron2Model.from_pretrained(\"tts_en_tacotron2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xsyBa9tIdHp4"},"source":["# Tacotron2 е SpectrogramGenerator\n","assert isinstance(model, SpectrogramGenerator)\n","\n","# SpectrogramGenerators во NeMo има 2 помошни функции:\n","#   1. parse(str_input: str, **kwargs) зема стринг на англиски јазик и продуцира тензор со токени\n","#   2. generate_spectrogram(tokens: 'torch.tensor', **kwargs) го зема тензорот со токени и генерира спектрограм\n","# Да ги пробаме:\n","tokens = model.parse(str_input = \"Hey, this produces speech!\")\n","spectrogram = model.generate_spectrogram(tokens = tokens)\n","\n","# Сега можеме да ги визуелизираме генерираните спектрограми\n","# Ако сакаме да генерираме говор, мора да користиме vocoder заедно со генератор на spectrogram.\n","from matplotlib.pyplot import imshow\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","imshow(spectrogram.cpu().detach().numpy()[0,...], origin=\"lower\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZ90eCfdrNIf"},"source":["# Тренирање\n","\n","Да видиме како може да се претренира Tacotron 2 одново.\n","\n"]},{"cell_type":"code","metadata":{"id":"7rHG-LERrPRY"},"source":["# NeMo скриптите за тренирање се наоѓаат во фолдерот examples/. \n","# Потребно е да ги преземеме скриптите tacotron2.py и tacotron2.yaml file\n","!wget https://raw.githubusercontent.com/NVIDIA/NeMo/r1.0.0rc1/examples/tts/tacotron2.py\n","!mkdir conf && cd conf && wget https://raw.githubusercontent.com/NVIDIA/NeMo/r1.0.0rc1/examples/tts/conf/tacotron2.yaml && cd .."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Upv_LxBIsC51"},"source":["Да ја погледнеме датотеката tacotron2.py\n","\n","```python\n","import pytorch_lightning as pl\n","\n","from nemo.collections.common.callbacks import LogEpochTimeCallback\n","from nemo.collections.tts.models import Tacotron2Model\n","from nemo.core.config import hydra_runner\n","from nemo.utils.exp_manager import exp_manager\n","\n","\n","# hydra_runner е NeMo врапер\n","# ја бара конфигурациската датотека tacotron2.yaml во conf фолдерот\n","# Hydra ја парсира yaml датотеката и ја враќа како Omegaconf DictConfig\n","@hydra_runner(config_path=\"conf\", config_name=\"tacotron2\")\n","def main(cfg):\n","    # Дефинираме Lightning trainer\n","    trainer = pl.Trainer(**cfg.trainer)\n","    # exp_manager е NeMo конструкција која помага при вчитување и зачувување на чекпоинтс\n","    exp_manager(trainer, cfg.get(\"exp_manager\", None))\n","    # Го дефинира Tacotron 2 моделот, тренингот и валидацијата\n","    model = Tacotron2Model(cfg=cfg.model, trainer=trainer)\n","    # Додава callbacks\n","    lr_logger = pl.callbacks.LearningRateMonitor()\n","    epoch_time_logger = LogEpochTimeCallback()\n","    trainer.callbacks.extend([lr_logger, epoch_time_logger])\n","    # Ја повикува lightning trainer's fit() за тренирање на моделот\n","    trainer.fit(model)\n","\n","\n","if __name__ == '__main__':\n","    main()  # noqa pylint: disable=no-value-for-parameter\n","```"]},{"cell_type":"markdown","metadata":{"id":"6nM-fZO-s75u"},"source":["Да ја погледнеме yaml конфигурацијата\n","\n","```yaml\n","name: &name Tacotron2\n","sample_rate: &sr 22050\n","# <PAD>, <BOS>, <EOS> ќе бидат додадени од tacotron2.py скриптата\n","labels: &labels [' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n","                 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']',\n","                 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n","                 'u', 'v', 'w', 'x', 'y', 'z']\n","n_fft: &n_fft 1024\n","n_mels: &n_mels 80\n","fmax: &fmax null\n","n_stride: &n_window_stride 256\n","pad_value: &pad_value -11.52\n","train_dataset: ???\n","validation_datasets: ???\n","```\n","\n","Првиот дел од yaml дефинира некои параметри користени од Tacotron. Може да забелешите дека ратата на семплирање е 22050 за податочното множество LJSpeech.\n","\n","Можеме да забележиме и дека `train_dataset: ???` и `validation_datasets: ???`. ??? укажува дека овие вредности мора да бидат пренесени преку командна линија, инаку скриптата нема да работи.\n","\n","Понатаму ги гледаме pytorch lightning trainer параметрите.\n","\n","```yaml\n","trainer:\n","  gpus: 1 # број на gpus\n","  max_epochs: ???\n","  num_nodes: 1\n","  accelerator: ddp\n","  accumulate_grad_batches: 1\n","  checkpoint_callback: False  # од страна на exp_manager\n","  logger: False  # од страна на exp_manager\n","  gradient_clip_val: 1.0\n","  flush_logs_every_n_steps: 1000\n","  log_every_n_steps: 200\n","  check_val_every_n_epoch: 25\n","```\n","\n","Овие вредности може да се сменат или преку уредување на yaml или преку командна линија.\n","\n","Да преземеме аудио податоци и да го тестираме Tacotron2."]},{"cell_type":"code","metadata":{"id":"GnEzODcorugt"},"source":["!wget https://github.com/NVIDIA/NeMo/releases/download/v0.11.0/test_data.tar.gz && mkdir -p tests/data && tar xzf test_data.tar.gz -C tests/data\n","\n","# Tacotron2 бара .json датотеки за дефинирање на тренинг и валидациските податоци.\n","!cat tests/data/asr/an4_val.json\n","\n","# Забелешка: Земеното податочно множество не е доволно за вистинско тренирање на Tacotron 2. \n","# Нема да резултира во квалитетен Tacotron 2 модел, но е доволно за илустрирање како да тренирате модел.\n","# За квалитетен Tacotron 2 потребна е голема порција податоци и тренирањето трае неколку недели.\n","!python tacotron2.py sample_rate=16000 train_dataset=tests/data/asr/an4_train.json validation_datasets=tests/data/asr/an4_val.json trainer.max_epochs=3 trainer.accelerator=null trainer.check_val_every_n_epoch=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9erGDGZJ1H_p"},"source":["# Податоци за тренирање\n","\n","За тренирање на Tacotron2, препорачливо е да употребите податочно множество со следните параметри:\n","  - Рата на семплирање од 22050Hz или повисока\n","  - Еден говорник\n","  - Говорот треба да содржи различни фонеми\n","  - Датотеките треба да се со должина од 1-10 секунди\n","  - Датотеките не треба да имаат „молк“ на почетокот и на крајот\n","  - Датотеките не треба да содржат долги сегменти со „молк“\n","\n","Откако ќе се добијат податоците и ќе се поделат на тренирачки, валидациски и тестирачки податоци, треба да се конструираат .json датотеки кои ќе му кажат на NeMo каде се наоѓаат овие аудио датотеки.\n","\n","На пример:\n","\n","```json\n","{\"audio_filepath\": \"/path/to/audio1.wav\", \"text\": \"the transcription\", \"duration\": 0.82}\n","{\"audio_filepath\": \"/path/to/audio2.wav\", \"text\": \"the other transcription\", \"duration\": 2.1}\n","...\n","```\n","Времетраењето е во секунди.\n","\n","Последно, обновете ги лабелите во Tacotron 2 yaml конфигурацијата доколку вашите податоци содржат различни карактери.\n","\n","Сега сте подготвени да ја стартувате скриптата:\n","```bash\n","python tacotron2.py train_dataset=YOUR_TRAIN.json validation_datasets=YOUR_VAL.json trainer.gpus=-1\n","```\n","\n","Честитки! Научивте како да направите модел за транслација на текст во говор!"]}]}